模型一：Regex Rule（基于规则的模型）
模型简介

Regex Rule 模型通过人工编写的正则表达式或关键词规则，对输入文本进行模式匹配并完成分类。该方法不依赖数据训练，完全基于人工经验和业务规则。

优点

不需要训练数据，适合冷启动场景

推理速度极快，几乎没有计算开销

规则逻辑清晰，结果高度可解释

在规则覆盖范围内准确率较高

缺点

泛化能力差，难以覆盖语言多样性

对文本表达变化非常敏感

规则数量增多后维护成本高

无法理解上下文和深层语义

适用场景

业务规则明确、意图固定的任务

系统兜底策略或初步过滤

模型二：TF-IDF + Machine Learning（传统机器学习模型）
模型简介

该模型首先使用 TF-IDF 方法将文本表示为向量，再结合传统分类算法（如逻辑回归、SVM、朴素贝叶斯）进行文本分类。

优点

实现简单，训练和推理速度快

对小规模数据集效果较好

相比规则系统具有一定泛化能力

对计算资源要求较低

缺点

词袋模型忽略词序和上下文信息

无法捕捉深层语义关系

对长文本和复杂表达能力有限

依赖人工特征工程和参数调优

适用场景

中小规模文本分类任务

对实时性要求较高的系统

模型三：BERT（预训练深度学习模型）
模型简介

BERT 是基于 Transformer 的预训练语言模型，通过大规模语料进行预训练，再在下游任务中进行微调，能够充分建模上下文语义信息。

优点

语义理解能力强，分类精度高

能建模上下文和长距离依赖

对语言表达变化具有良好鲁棒性

在多数 NLP 任务中表现优异

缺点

模型参数量大，计算资源消耗高

训练和推理成本较高

模型结构复杂，可解释性较弱

在小数据集上可能出现过拟合

适用场景

对精度要求高的文本理解任务

数据量和计算资源充足的场景

模型四：Prompt（基于大模型的提示学习方法）
模型简介

Prompt 方法基于大规模预训练语言模型，通过设计自然语言提示，引导模型直接完成分类任务，通常无需或仅需极少训练数据。

优点

几乎不需要训练数据，开发效率高

迁移能力强，适应新任务快

能理解复杂语义和上下文

可统一处理多种 NLP 任务

缺点

推理成本高，依赖大模型服务

输出结果对 Prompt 设计较敏感

结果稳定性和可控性较弱

输出格式难以严格约束

适用场景

快速原型验证

小样本或零样本任务

多任务统一处理场景
