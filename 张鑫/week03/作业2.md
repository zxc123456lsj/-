# 汽车行业意图识别项目：模型方案优缺点分析报告

## 1. 正则表达式方案 (Regex Rule-based)
**实现逻辑**：基于 `config.py` 中预定义的关键词规则库，通过关键词匹配进行分类。

### 优点：
*   **性能极高**：推理延迟几乎为零，不占用 CPU/GPU 推理资源。
*   **准确率 100%（针对特定指令）**：只要命中规则，分类结果绝对准确且可控。
*   **无需训练数据**：只要有业务经验，即可快速上线。
*   **完全可解释性**：为什么归到这一类，可以通过匹配的关键词直接回溯。

### 缺点：
*   **泛化能力极差**：无法处理同义词、错别字或语序变化（例如：能匹配“播放音乐”，但无法匹配“给爷整点曲子”）。
*   **维护成本极高**：随着意图增加（如项目要求的 20+ 意图），规则冲突会剧增，逻辑变得极其复杂。
*   **无法处理长尾意图**：对于表达含糊或复杂的意图无能为力。

---

## 2. TF-IDF + 统计机器学习 (SVM)
**实现逻辑**：利用 `jieba` 分词和 `TfidfVectorizer` 提取特征，使用 `LinearSVC` 进行线性分类。

### 优点：
*   **推理速度快**：虽然慢于正则，但远快于深度学习模型，能轻松满足 <400ms 的延迟要求。
*   **训练成本低**：不需要 GPU 即可完成万级数据的快速迭代。
*   **稳定性好**：在样本量较少且类别分布不均的情况下，逻辑回归或 SVM 往往比复杂模型更稳健。

### 缺点：
*   **丢失语义语序**：基于“词袋模型”，无法识别词序带来的语义变化（例如：“我给孩子洗澡”和“孩子给我洗澡”特征相同）。
*   **依赖分词质量**：中文分词如果出现歧义（如 `jieba` 的切分错误），会直接影响特征准确性。
*   **特征稀疏**：对于短文本（汽车指令多为短句），TF-IDF 提取的特征非常有限，上限明显。

---

## 3. BERT 深度学习 (Fine-tuning)
**实现逻辑**：基于 `bert-base-chinese` 预训练模型进行下游任务微调（Fine-tuning）。

### 优点：
*   **语义理解能力强**：能够理解上下文、语义相近但措辞不同的指令，泛化性极佳。
*   **准确率上限高**：在高质量数据集下，是达成项目“95%准确率”目标的核心手段。
*   **处理长短文本皆宜**：不受限于关键词，能捕捉复杂的语言特征。

### 缺点：
*   **推理延迟高**：从日志和文档可见，BERT 在 CPU 上的推理可能接近阈值，需要高性能推理引擎（ONNX/TensorRT）或 GPU。
*   **资源消耗大**：模型文件较大（约 400MB+），对车载嵌入式设备的内存和显存有一定要求。
*   **训练缓慢**：需要 GPU 进行数轮迭代，且容易出现过拟合。

---

## 4. 大语言模型 (GPT/Prompt Engineering + RAG)
**实现逻辑**：基于本地部署的小模型（Qwen 2.5:0.5B），配合 TF-IDF 检索出的 Top-10 历史例子作为动态提示词（Dynamic Few-shot）。

### 优点：
*   **极致的泛化性**：对于完全没见过的新意图，LLM 也能根据语义做出常识判断。
*   **零/少样本学习**：无需大量标注数据，只需提供几个典型例子（Prompt）即可。
*   **逻辑兜底**：适合处理“Other”类或其他模型置信度极低的复杂场景。

### 缺点：
*   **延迟挑战严重**：日志显示模型出现过 `502 Bad Gateway` 和多次重试，在高并发压测下难以稳定在 400ms 内。
*   **输出不确定性**：LLM 存在“幻觉”风险，可能输出不在列表内的类别。
*   **系统复杂性**：需要维护向量检索（或 TF-IDF 检索）和本地 LLM 推理服务器（如 Ollama）。
