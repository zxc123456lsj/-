> 作业2：阅读项目计划书  + 初步项目代码，写清楚四个模型的优缺点，形成一个word/markdown提交。

## 一、正则

#### 优点

1. **高效精确匹配**
   - 时间复杂度：O(n)，线性扫描，速度极快
   - 内存占用：极低，仅需存储模式字符串
   - 适用于：结构化文本提取、格式验证

2. **规则明确可控**
   - 模式完全由开发者定义
   - 可预测性强，无随机性
   - 调试和维护相对简单

3. **无需训练数据**
   - 零样本学习能力
   - 不依赖大规模标注数据
   - 部署成本极低

4. **跨语言平台兼容性**
   - 几乎所有编程语言都支持
   - 不依赖特定框架或硬件

#### 缺点

1. **无法处理语义**
   - 仅基于字符模式匹配
   - 不理解上下文含义
   - 无法处理同义词、近义词

2. **模式维护困难**
   - 复杂模式可读性差
   - 微小的改动可能影响整个模式
   - 需要专业知识编写复杂表达式

3. **泛化能力差**
   - 无法处理未见过的表达方式
   - 对输入格式变化敏感
   - 规则会随着需求变化而快速过时

4. **扩展性有限**
   - 难以处理多层次嵌套结构
   - 长距离依赖关系处理困难

✅ 适用场景：
   - 数据清洗和格式化
   - 日志文件解析
   - 简单模式验证（邮箱、电话等）
   - 批量文本替换

❌ 不适用场景：
   - 语义理解任务
   - 情感分析
   - 文本分类（复杂类别）
   - 生成式任务

## TF-IDF

#### 优点

1. **计算效率高**
   - 训练复杂度：O(n×d)，n为文档数，d为词汇量
   - 推理速度：O(d)，向量点乘运算
   - 内存效率：稀疏矩阵存储

2. **可解释性强**
   - 特征权重有明确的数学意义
   - 可识别文档中的关键词
   - 结果容易理解和验证

3. **无监督/半监督能力**
   - 不需要大量标注数据
   - 可应用于聚类任务
   - 支持增量学习

4. **领域适应快**
   - 仅需新的文档集合
   - 无需重新训练复杂模型
   - 对新领域适应性强

#### 缺点

1. **忽略词序和语义**
   - 词袋模型假设
   - "北京烤鸭" ≠ "烤鸭在北京"
   - 无法捕捉上下文关系

2. **高维稀疏问题**
   - 特征维度通常上万
   - 稀疏矩阵占用内存
   - 维度过高导致维度灾难

3. **无法处理未登录词**
   - 只认识训练时出现的词汇
   - 需要额外的OOV处理机制
   - 对新鲜词汇不友好

4. **语义信息损失**
   - 同义词权重不同
   - 多义词无法区分
   - 缺乏深层语义理解

✅ 适用场景：
   - 文档相似度计算
   - 关键词提取
   - 简单文本分类（类别少）
   - 搜索引擎相关度排序

❌ 不适用场景：
   - 语义相似度判断
   - 复杂意图识别
   - 需要上下文理解的任务
   - 生成式任务

## BERT

#### 优点

1. **深度语义理解**
   - 双向上下文编码
   - 可捕捉长距离依赖
   - 理解深层语义关系

2. **强大的预训练能力**
   - 在大规模语料上预训练
   - 学习丰富的语言知识
   - 迁移学习效果好

3. **统一框架多任务**
   - 支持分类、NER、QA等任务
   - 同一模型不同下游任务
   - 参数共享，效率高

4. **开源生态完善**
   - Hugging Face等丰富资源
   - 多种预训练变体
   - 活跃的社区支持

#### 缺点

1. **计算资源需求高**
   - 训练：需要GPU集群，成本高
   - 推理：实时性要求高时可能延迟
   - 模型大小：基础版110M参数，大版本340M+

2. **训练数据依赖**
   - 需要大量标注数据微调
   - 领域迁移可能效果下降
   - 对小样本任务不够友好

3. **可解释性差**
   - 黑盒模型，决策难解释
   - 特征学习过程不透明
   - 调试困难

4. **生成能力有限**
   - 主要是编码器架构
   - 文本生成能力弱
   - 需要额外解码器



✅ 适用场景：
   - 文本分类（特别是细粒度）
   - 命名实体识别
   - 情感分析
   - 问答系统
   - 语义相似度计算

❌ 不适用场景：
   - 资源受限的移动设备
   - 实时性要求极高的场景
   - 需要强解释性的应用
   - 创意文本生成

## GPT-4

#### 优点

1. **强大的生成能力**
   - 创造性文本生成
   - 上下文相关回复
   - 多轮对话保持一致性

2. **多模态理解**
   - 文本+图像理解
   - 跨模态推理
   - 复杂指令理解

3. **零样本/小样本学习**
   - 无需微调即可执行任务
   - 任务描述即能力
   - 强大的泛化能力

4. **复杂推理能力**
   - 逻辑推理
   - 数学计算
   - 代码生成
   - 多步骤问题求解

#### 缺点

1. **成本极高**
   - API调用费用：$0.03/1K tokens（输入）
   - 私有部署成本：数百万美元级
   - 训练成本：数百万美元计算资源

2. **不可控风险**
   - 可能生成虚假信息
   - 存在偏见和伦理问题
   - 输出结果不可预测

3. **延迟和可用性**
   - API调用有延迟
   - 服务可用性依赖第三方
   - 隐私数据安全问题

4. **定制化困难**
   - 模型参数不可调整
   - 领域特定知识有限
   - 更新周期不可控

✅ 适用场景：
   - 创意内容生成
   - 复杂问答系统
   - 代码辅助开发
   - 多轮对话机器人
   - 多模态任务处理

❌ 不适用场景：
   - 预算有限的项目
   - 需要完全可控输出的场景
   - 实时性要求极高的应用
   - 处理敏感隐私数据



