## 一、规则匹配模型（Regex Rule Model）

### 1. 模型说明

规则模型基于人工编写的正则表达式（Regex），通过关键词或模式匹配的方式判断用户意图。在本项目中，对每个意图类别配置一组正则规则，当输入文本命中规则时即返回对应类别。

**对应代码**：`regex_rule.py`

---

### 2. 优点

- **可解释性极强**：命中规则即命中意图，结果透明
- **推理速度极快**：无需向量化与模型计算，毫秒级响应
- **资源消耗极低**：不依赖 GPU 或复杂模型
- **适合冷启动**：在数据极少时仍可工作

---

### 3. 缺点

- **依赖人工规则维护**：规则数量增长后维护成本极高
- **泛化能力差**：难以覆盖语言多样性与表达变化
- **无法处理歧义与隐含语义**
- **难以扩展到大规模意图类别**

---

## 二、TF-IDF + 传统机器学习模型

### 1. 模型说明

该方案使用 **TF-IDF** 将文本转为稀疏向量，再使用传统分类器（如 Logistic Regression / SVM）进行意图分类。

**对应代码**：`tfidf_ml.py`

---

### 2. 优点

- **实现简单、训练速度快**
- **对小数据集友好**
- **推理效率高，延迟低**
- **相比规则模型具备一定泛化能力**

---

### 3. 缺点

- **无法建模上下文与语序信息**
- **特征高度稀疏，表达能力有限**
- **对同义表达、语义相近句子不敏感**
- **精度存在明显上限**

---

## 三、大模型 Prompt + TF-IDF 检索增强方案（LLM）

### 1. 模型说明

该方案通过 **TF-IDF 检索相似样本**，将历史示例动态拼接到 Prompt 中，调用大语言模型（如 GPT）完成意图分类。

**对应代码**：`prompt.py`

---

### 2. 优点

- **语义理解能力最强**
- **几乎无需训练，零/小样本即可使用**
- **对复杂表达、长文本、歧义文本鲁棒性强**
- **快速支持新意图、新领域**

---

### 3. 缺点

- **推理成本高（API 调用费用）**
- **响应时间不稳定，延迟较高**
- **存在幻觉与不一致输出风险**
- **对 Prompt 设计高度敏感**

---

## 四、BERT 深度学习模型（Fine-tuning）

### 1. 模型说明

基于预训练语言模型 BERT，对下游意图分类任务进行微调（Fine-tuning），通过 Transformer 编码器获取上下文语义表示。

**对应代码**：`bert.py`

---

### 2. 优点

- **语义建模能力强，精度高**
- **上下文感知能力优秀**
- **输出稳定、一致性好**
- **可离线部署，适合工程落地**

---

### 3. 缺点

- **模型体积大，推理资源消耗高**
- **训练成本高，对数据质量敏感**
- **部署复杂（模型加载、显存管理）**

---


