# Week3_李丽_四种模型优缺点分析
sorrry老师，我最近项目忙，没有时间看完这个项目，以下内容是我看了一半再让AI生成的，周五我会继续看的

## bert（深度学习预训练模型）
- 实现原理 : 加载 bert-base-chinese 预训练模型，在自定义数据集上进行微调 (Fine-tuning)。
- 优点 :
  - 语义理解最强 : 能真正“读懂”句子的上下文、同义词和多义词，准确率通常是最高的（SOTA）。
  - 泛化性好 : 即使没见过的句式，只要语义相近也能识别。
- 缺点 :
  - 资源消耗大 : 训练需要 GPU，推理速度较慢（项目文档提到需优化以满足 400ms 要求）。
  - 模型体积大 : 权重文件通常有几百 MB，部署成本高。
  - 黑盒 : 很难解释为什么模型分错了。
## prompt（大模型）
- 实现原理 : RAG (检索增强生成) 思路。先用 TF-IDF 检索出最相似的历史 10 个例子，作为 prompt 的一部分发给 LLM (如 Qwen/OpenAI)，让大模型做选择题。
- 优点 :
  - 零样本/少样本能力 : 不需要训练，只要给几个例子（Few-shot）就能通过逻辑推理出结果。
  - 处理长尾/复杂问题 : 对极其口语化、复杂的指令理解能力最强。
- 缺点 :
  - 延迟极高 : 依赖网络请求或庞大的本地推理，通常需要秒级响应，不适合实时性要求高的车载场景。
  - 成本高 : Token 是要钱的（API）或算力是要钱的（本地部署）。
  - 不可控（幻觉） : 可能会输出“我不知道”、“好的”等非标准格式，需要额外的解析逻辑。
## regex_rule(正则表达式)
- 实现原理 : 在 config.py 中定义关键词字典（如 ["播放", "电视剧"] ），通过 Python re 模块进行关键词匹配。
- 优点 :
  - 速度极快 : 几乎没有计算开销，微秒级响应。
  - 可控性强 : 规则写什么就配什么，对于“打开空调”、“播放音乐”等固定指令准确率 100%。
  - 无需训练 : 不需要数据，写好规则即刻上线。
- 缺点 :
  - 泛化能力差 : 只能匹配写死的词，用户换个说法（如“来点声音” vs “播放音乐”）就失效。
  - 维护困难 : 随着意图增加，规则会变得极其复杂且容易冲突。
  - 无语义理解 : 无法区分“我不看电影”和“我要看电影”（只匹配关键词）。

## tfidf_ml(TF-IDF+深度学习)
- 实现原理 : 使用 jieba 分词 -> 去除停用词 -> 计算词频逆文档频率 (TF-IDF) -> 输入线性支持向量机 (LinearSVC) 进行分类。
- 优点 :
  - 轻量高效 : 训练和推理速度都很快（毫秒级），CPU 就能跑得飞快。
  - 鲁棒性尚可 : 比正则强，能通过统计规律处理一定的泛化情况。
  - 可解释性 : 可以通过查看权重知道哪些词对分类贡献最大。
- 缺点 :
  - 忽略语序 : 属于“词袋模型”，无法理解“猫吃鱼”和“鱼吃猫”的区别。
  - 特征工程繁琐 : 需要维护停用词表，对未登录词（没见过的词）处理能力差。
## 总结
- 先用 正则 拦截高频固定指令（如“退出”、“静音”），速度最快。
- 正则搞不定的，丢给 BERT/TF-IDF 进行常规语义识别。
- 如果 BERT 置信度低，或者是极复杂的长尾指令，最后才调用 GPT 兜底
