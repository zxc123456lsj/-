### 1. BERT 模型 (bert.py)

基于预训练的 Transformer 架构进行微调。

*   **优点**：

    *   **语义理解强**：能够理解上下文和词序，对同义词、句式变换有很好的鲁棒性。例如，“打开空调”和“太热了，降温”都能被识别为同一意图。
    *   **准确率高**：在有充足标注数据的情况下，通常能达到项目要求的 95% 准确率。
    *   **代码实现成熟**：代码中使用 Transformers 库加载预训练模型，流程标准，易于维护。
*   **缺点**：

    *   **推理延迟较高**：相比正则和 TF-IDF，BERT 计算量大。如果不进行模型量化（Quantization）或使用 ONNX Runtime 加速，在普通 CPU 上可能逼近或超过 400ms 的延迟红线。
    *   **依赖标注数据**：需要一定量的“高质量标注数据集”进行微调，冷启动成本高于 LLM。

### 2. GPT / 大模型 (prompt.py)

代码中采用了 RAG（检索增强生成）思路，先用 TF-IDF 检索相似的历史例子，再动态构建 Prompt 请求大模型分类。

*   **优点**：

    *   **泛化能力极强**：对于“长尾意图”或从未见过的用户口语化表达（如“搞点周杰伦的调调”），理解能力远超 BERT。
    *   **少样本学习**：代码中通过 PROMPT\_TEMPLATE 和动态检索 Top10 相似案例，无需训练即可实现高精度分类。
    *   **开发速度快**：不需要复杂的训练流程，调整 Prompt 即可优化。
*   **缺点**：

    *   **延迟无法达标**：网络请求（HTTP）+ 大模型生成 Token 的时间通常在 1秒以上，远超 400ms 的要求，无法满足车载实时控制。
    *   **成本高昂**：Token 费用随着请求量增加而线性增长。
    *   **幻觉风险**：虽然有 Prompt 约束，但仍可能输出非预定义的类别。

### 3. 正则表达式 (regex\_rule.py)

基于关键词匹配的硬规则逻辑。

*   **优点**：

    *   **速度极快**：延迟基本可以忽略不计（<1ms），完全满足实时性要求。
    *   **结果可控**：由规则定义，不会出现“黑盒”模型的不可解释性错误。
    *   **冷启动快**：无需数据，写好规则即刻上线。
*   **缺点**：

    *   **泛化能力极差**：无法处理未定义的句式。例如若规则写了“打开空调”，用户说“开一下冷气”可能就无法识别。
    *   **维护成本高**：随着 20+ 个意图的扩展，规则库会变得极其庞大且容易冲突，难以覆盖所有自然语言的变化。

### 4. TF-IDF + 机器学习 (tfidf\_ml.py)

传统的词袋模型配合分类器。

*   **优点**：

    *   **速度快**：推理速度远快于 BERT，略慢于正则，完全满足 400ms 要求。
    *   **轻量级**：模型文件小，部署几乎不占用资源。
    *   **基线效果尚可**：在关键词明显的分类任务中（如“导航到X”），效果不错。
*   **缺点**：

    *   **缺乏语义理解**：基于词频统计，忽略了词序和上下文。无法区分“不开空调”和“开空调”（如果停用词处理不当或否定词权重不够）。
    *   **上限低**：面对复杂的口语化表达，准确率很难提升到 95% 以上。

