## 1. BERT 模型
把文本喂给预训练语言模型,训练交叉熵
- 优点

1. 效果上限高：能理解中文语义、同义表达、语序变化、长短句差异。

2. 泛化强：对“没见过的句式/词”也能猜对，尤其是意图类任务。

3. 减少特征工程：不需要你手工做关键词规则。

- 缺点
1. 训练/推理成本更高.

2. 数据量敏感,容易过拟合/不稳，需要正则、早停、学习率调参。


## TF-IDF

- 优点

1. 非常快、成本低：实现简单，迭代快。

2. 小数据也能跑得不错：尤其当类别靠关键词区分明显时。

3. 可解释性强：能直接看每个类别权重最高的词。

- 缺点

1. 语义能力弱：同义词、改写、口语化、错别字、分词差异都会掉点，无法理解语义。

2. 非常依赖分词结果，如果分词分错，统计值的意义会大打折扣

3. 类别均衡的数据很重要。



## 调用大语言模型（LLM）
把“允许的标签集合 + 定义 + 示例”写进 prompt，让模型直接输出最匹配的标签

- 优点

1. 几乎零训练：你有新类别、新话术，改 prompt

2. 语义很强：对改写、口语、混合信息、上下文都很稳。

3. 上线快：适合做原型、冷启动、类别经常变的业务。

- 缺点

1. 成本/延迟：每次请求要花钱、要等；大规模调用贵。

2. 一致性问题：同一句话在不同温度/不同时间可能输出略不同；需要约束输出（比如只允许输出 label 列表）。

3. 数据合规/隐私：如果文本敏感，需要合规处理或本地模型。


## 正则表达式
写规则：匹配到“天气/温度/下雨” → Weather；匹配“播放/来一首/歌曲” → Music；匹配“车票/到…/路线” → Travel。

- 优点

1. 极强可控、可解释：为什么判这个类一眼明白。

2. 零训练成本、速度极快：本地瞬间完成。

3. 在关键词非常稳定时准确率很高：比如“播放/天气/导航”这种强触发词。

- 缺点

1. 维护成本高：规则越写越多，冲突、边界情况多（例如“别播放”是否算 Music？）。

2. 召回差：同义表达、隐式表达、口语化很容易漏掉。

3. 扩展难：类别多或表达多样时会爆炸。