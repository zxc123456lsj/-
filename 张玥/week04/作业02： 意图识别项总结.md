# 作业02： 意图识别项目总结

## 一、项目背景与目标

本次作业基于 **01-intent-classify** 项目，完成一个支持多模型的文本意图识别系统。项目目标包括：

- 在本地成功配置并运行完整工程
- 理解并对比 **规则模型、传统机器学习模型、深度学习模型、大模型接口** 在意图识别任务中的差异
- 通过 FastAPI 进行统一服务化封装，并完成接口调用验证

------

## 二、系统整体架构

系统采用模块化设计，将不同类型的模型以“并行策略”的方式集成到同一服务中：

1. **规则模型（Regex）**
   - 基于人工规则与关键词匹配
   - 响应速度最快，适合强约束场景
2. **TF-IDF + 传统机器学习模型（LinearSVC）**
   - 使用 TF-IDF 表征文本特征
   - 结合线性分类器完成意图判断
   - 推理速度快，但依赖人工特征工程
3. **BERT 深度学习模型**
   - 基于预训练 BERT 的语义表示能力
   - 能理解上下文语义信息，泛化能力更强
4. **GPT 大模型接口**
   - 通过 Prompt 方式调用大模型完成意图判断
   - 推理准确率高，但响应时间相对较长

所有模型通过 FastAPI 统一对外暴露接口，便于测试、对比和组合使用。

------

## 三、环境配置与关键实现

### 1. 本地环境配置

- 使用 Conda 管理 Python 3.12 环境
- 解决了 transformers、scikit-learn 版本不一致导致的模型反序列化警告
- 采用 **本地离线加载 BERT 模型文件**，避免对 HuggingFace 在线下载的依赖

### 2. 模型加载与推理

- BERT 模型通过 `AutoTokenizer` 与 `BertForSequenceClassification` 从本地目录加载
- 加载下游任务训练得到的权重文件 `bert.pt`
- 在 FastAPI 启动阶段完成模型初始化，避免重复加载带来的性能问题

### 3. 接口部署

- 使用 FastAPI + Uvicorn 启动服务
- 自动生成 Swagger 文档页面（/docs）
- 提供统一 JSON 请求与响应格式
- 运行成功截图如下：![image-20260205004310695](C:\Users\ROG\AppData\Roaming\Typora\typora-user-images\image-20260205004310695.png)

------

## 四、接口验证结果

本项目共提供 **四个文本分类接口**，均已在本地验证通过：

- `/v1/text-cls/regex`
- ![image-20260205004608793](C:\Users\ROG\AppData\Roaming\Typora\typora-user-images\image-20260205004608793.png)`/v1/text-cls/tfidf`
- ![image-20260205004642510](C:\Users\ROG\AppData\Roaming\Typora\typora-user-images\image-20260205004642510.png)
- `/v1/text-cls/bert`
- ![image-20260205004936585](C:\Users\ROG\AppData\Roaming\Typora\typora-user-images\image-20260205004936585.png)
- `/v1/text-cls/gpt`
- ![image-20260205005044708](C:\Users\ROG\AppData\Roaming\Typora\typora-user-images\image-20260205005044708.png)

### 示例：GPT 接口调用结果

输入文本：

> “播放周杰伦的音乐”

返回结果：

```json
{
  "request_id": "1",
  "request_text": "播放周杰伦的音乐",
  "classify_result": ["Music-Play"],
  "classify_time": 3.119,
  "error_msg": "ok"
}
```

说明：

- 四个接口均返回 HTTP 200
- 分类结果正确
- GPT 接口推理时间相对较长，但语义理解能力最强

------

## 五、问题与解决过程

- **问题 1**：BERT 接口请求后页面长时间无响应
  **原因**：调试过程中误进入 `pdb` 断点，导致 FastAPI 主线程阻塞
  **解决**：移除断点后，接口恢复正常
- **问题 2**：本地模型路径被识别为 HuggingFace repo_id
  **解决**：明确使用本地目录结构，并保证 tokenizer 与模型文件完整

------

## 六、实验结论与思考

- 不同模型在 **准确率、响应速度、工程复杂度** 方面各有优劣
- 实际系统中可采用“规则 + 小模型 + 大模型兜底”的组合策略
- 本项目完整体验了 NLP 系统从 **模型 → 服务 → 接口调用** 的工程化流程

------

## 七、课堂汇报一句话总结

> 本次作业完成了一个支持规则、传统机器学习、BERT 以及 GPT 的多模型意图识别系统，并成功实现了本地部署、服务化封装和接口验证，重点验证了完整的工程流程与系统架构设计能力。